<document>
  <properties>
    <title>UIMA Conceptual Overview</title>
  </properties>
<body>



<div class="chapter">
<div class="Section1">



<section name="UIMA Conceptual Overview"><a id="_crossRef320"> </a>



<p>UIMA is an open, industrial-strength, scaleable and
extensible platform for creating, integrating and deploying unstructured
information management solutions from powerful text or multi-modal analysis and
search components. </p>

<p>IBM is making the UIMA SDK available as free software to
provide a common foundation for industry and academia to collaborate and
accelerate the world-wide development of technologies critical for discovering
vital knowledge present in the fastest growing sources of information today.</p>

<p>This chapter presents an introduction to many essential
UIMA concepts. It is meant to provide a broad overview to give the reader a
quick sense of UIMA&rsquo;s basic architectural philosophy and the UIMA SDK&rsquo;s
capabilities. </p>

<p>This chapter provides a general orientation to UIMA and
makes liberal reference to the other chapters in the UIMA SDK documentation
set, where the reader may find detailed treatments of key concepts and
development practices. It may be useful to refer to <b><a class="crossrefText" href="UIMA Glossary.htm#_crossRef344">Glossary of Key
Terms and Concepts</a></b> <a class="crossrefPage" href="UIMA Glossary.htm#_crossRef344"></a> , to become familiar with the terminology in this
overview.</p>



<subsection name="UIMA Introduction"><a id="_crossRef321"> </a>



<p><img alt="" width="576" height="376"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image002.png"/>
<a class="figCaption" id="uco1">UIMA helps you build the bridge between the unstructured and structured worlds</a>
Unstructured
information represents the largest, most current and fastest growing source of
information available to businesses and governments.  The web is just the tip of the iceberg.
Consider the mounds of information hosted in the enterprise and around the world
and across different media including text, voice and video.  The high-value content in these vast
collections of unstructured information is, unfortunately, buried in lots of
noise.  Searching for what you need or doing
sophisticated data mining over unstructured information sources presents new
challenges. </p>

<p>An unstructured information management (UIM) application
may be generally characterized as a software system that analyzes large volumes
of unstructured information (text, audio, video, images, etc.) to discover,
organize and deliver relevant knowledge to the client or application end-user.
An example is an application that processes millions of medical abstracts to
discover critical drug interactions. Another example is an application that
processes tens of millions of documents to discover key evidence indicating
probable competitive threats. </p>

<p>First and foremost, the unstructured data must be analyzed
to interpret, detect and locate concepts of interest that are not explicitly
tagged or annotated in the original artifact, for example, named entities like
persons, organizations, locations, facilities, products etc. More challenging
analytics may detect things like opinions, complaints, threats or facts.  And then there are relations, for example,
located in, finances, supports, purchases, repairs etc. The lists of concepts
important for applications to detect and find in unstructured resources are
large and often domain specific. Specialized component analytics must be
combined and integrated to do the job. </p>

<p>The result of analysis must, in turn, be put in structured
forms so that powerful data mining and search technologies like search engines,
database engines or OLAP (On-Line Analytical Processing, or Data Mining)
engines may be leveraged to efficiently find the concepts you need, when you need
them. </p>

<p>In analyzing unstructured content, UIM applications make
use of a variety of analysis technologies including:</p>

<ul><li>Statistical and rule-based Natural
Language Processing (NLP)</li>


<li>Information Retrieval (IR)</li>


<li>Machine learning</li>


<li>Ontologies</li>


<li>Automated reasoning and</li>


<li>Knowledge Sources (e.g., CYC,
WordNet, FrameNet, etc.)
</li></ul>

<p>These technologies are developed independently by highly
specialized scientists and engineers using different techniques, interfaces and
platforms. </p>

<p>The bridge from the unstructured world to the structured
world is built through the composition and deployment of these analysis
capabilities. This integration is often a costly challenge. </p>

<p>The Unstructured Information Management Architecture
(UIMA) is an architecture and software framework that helps you build that
bridge. It supports creating, discovering, composing and deploying a broad
range of analysis capabilities and linking them to structured information
services.</p>

<p>UIMA allows development teams to match the right skills with
the right parts of a solution and helps enable rapid integration across
technologies and platforms using a variety of different deployment options.
These ranging from tightly-coupled deployments for high-performance,
single-machine, embedded solutions to parallel and fully distributed
deployments for highly flexible and scaleable solutions.</p>




  </subsection>
<subsection name="The Architecture, the Framework and the SDK"><a id="_crossRef322"> </a>



<p>UIMA is a software architecture which specifies component
interfaces, data representations, design patterns and development roles for
creating, describing, discovering, composing and deploying multi-modal analysis
capabilities.</p>

<p>The <b><i>UIMA framework</i></b> provides a run-time
environment in which developers can plug in their UIMA component
implementations and with which they can build and deploy UIM applications. The
framework is not specific to any IDE or platform.</p>

<p>The <b><i>UIMA Software Development Kit (SDK)</i></b>
includes an all-Java implementation of the UIMA framework for the
implementation, description, composition and deployment of UIMA components and
applications. It also provides the developer with an Eclipse-based (<a
href="http://www.eclipse.org/">www.eclipse.org</a>) development environment
that includes a set of tools and utilities for using UIMA. </p>




  </subsection>
<subsection name="Analysis Basics"><a id="_crossRef323"> </a>



<div class="keyConcept">

<p><b>Key UIMA Concepts
Introduced in this Section</b>: Analysis Engine, Document, Annotator, Annotator
Developer, Type, Type System, Feature, Annotation, CAS, Sofa, JCas, UIMA
Context.</p>

</div>

<h3><a id="_crossRef324">Analysis Engines, Annotators and
Analysis Results</a></h3>

<p><img alt="" width="594" height="376"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image004.png"/>
<a class="figCaption" id="_crossRef325">Illustration of objects that
     might be represented in the UIMA Common Analysis Structure (CAS)</a>
</p>

<p>UIMA is an architecture in which basic building blocks
called Analysis Engines (AEs) are composed to analyze a document and infer and
record descriptive attributes about the document as a whole, and/or about
regions therein. This descriptive information, produced by AEs is referred to generally
as <b>analysis results</b>. Analysis results typically represent meta-data
about the document content. One way to think about AEs is as software agents
that automatically discover and record meta-data about original content.</p>

<p>UIMA supports the analysis of different modalities
including text, audio and video. The majority of examples we provide are for
text. We use the term <b><i>document, </i></b>therefore<b><i>,</i></b> to
generally refer to any unit of content that an AE may process, whether it is a
text document or a segment of audio, for example. See the section <a class="crossrefPage" href="UIMA Conceputal Overview.htm#_crossRef337"></a> for more information on multimodal processing in
UIMA.</p>

<p>Analysis results include different statements about the
content of a document. For example, the following is an assertion about the
topic of a document:</p>

<p class="xmp"><code>(1) The Topic of document D102 is &quot;CEOs and Golf&quot;. </code></p>

<p>Analysis results may include statements describing regions
more granular than the entire document.  We use the term <b><i>span</i></b> to refer to a sequence of characters
in a text document.  Consider that a
document with the identifier D102 contains a span, &quot;Fred
 Centers&quot; starting at character
position 101. An AE that can detect persons in text may represent the following
statement as an analysis result:</p>



<p class="xmp"><code>(2) The span from position 101 to 112 in document D102 denotes a Person</code></p>

<p>In both statements 1 and 2 above there is a special
pre-defined term or what we call in UIMA a <b><i>Type</i></b>. They are <i>Topic</i>
and <i>Person</i> respectively. UIMA types characterize the kinds of results
that an AE may create &ndash; more on types later.</p>

<p>Other analysis results may relate two statements.  For example, an AE might record in its
results that two spans are both referring to the same person:</p>

<p class="xmp"><code>(3) The Person denoted by span 101 to 112 and the Person denoted by span 141 to 143 in document D102 refer to the same Entity.</code></p>

<p>The above statements are some examples of the kinds of
results that AEs may record to describe the content of the documents they
analyze.  These are not meant to indicate
the form or syntax with which these results are captured in UIMA &ndash; more on that
later in this overview.</p>

<p>The UIMA framework treats Analysis engines as pluggable,
composible, discoverable, managed objects. At the heart of AEs are the analysis
algorithms that do all the work to analyze documents and record analysis results.
</p>

<p>UIMA provides a basic component type intended to house the
core analysis algorithms running inside AEs.  Instances of this component are called <b><i>Annotators</i></b>.  The analysis algorithm developer&rsquo;s primary
concern therefore is the development of annotators. The UIMA framework provides
the necessary methods for taking annotators and creating analysis engines. </p>

<p>In UIMA the person who codes analysis algorithms takes on
the role of the <b><i>Annotator Developer</i></b>.  <a class="crossrefText" href="Annotator_and_Analysis_Engine_Developers_Guide.htm#_crossRef1">Chapter
4, <b>Annotator
and Analysis Engine Developer&rsquo;s Guide</b></a> will take the reader through the details
involved in creating UIMA annotators and analysis engines.</p>

<p>At the most primitive level an AE wraps an annotator
adding the necessary APIs and infrastructure for the composition and deployment
of annotators within the UIMA framework.  The simplest AE contains exactly one annotator at its core. Complex AEs
may contain a collection of other AEs each potentially containing within them
other AEs. </p>

<h3><a id="_crossRef326">Representing Analysis Results in
the CAS</a></h3>

<p>How annotators represent and share their results is an
important part of the UIMA architecture.  UIMA defines a <b><i>Common Analysis Structure (CAS)</i></b> precisely
for these purposes.  </p>

<p>The CAS is an object-based data structure that allows the
representation of objects, properties and values. Object types may be related
to each other in a single-inheritance hierarchy.  The CAS logically (if not physically)
contains the document being analyzed. Analysis developers share and record
their analysis results in terms of an object model within the CAS.

<span class="footnote">
We have plans to extend the representational capabilities of the CAS and align
its semantics with the semantics of the OMG&rsquo;s Essential Meta-Object Facility
(EMOF) and with the semantics of the Eclipse Modeling Framework&rsquo;s (<a
href="http://www.eclipse.org/emf/">http://www.eclipse.org/emf/</a> ) Ecore
semantics and XMI-based representation.
</span> </p>

<p>The UIMA framework includes an implementation and
interfaces to the CAS. For a more detailed description of the CAS and its
interfaces see <a class="crossrefText" href="CAS_Reference.htm#_crossRef77">Chapter 26, <b>CAS
Reference</b></a>.</p>

<p>A CAS that logically contains statement 2 (repeated here
for your convenience)</p>

<p class="xmp"><code>(2) The span from position 101 to 112 in document D102 denotes a Person</code></p>

<p>would include objects of the Person type. For each person
found in the body of a document, the AE would create a Person object in the CAS
and link it to the span of text where the person was mentioned in the document.</p>

<p>While the CAS is a general purpose representational
structure, UIMA defines a few basic types and affords the developer the ability
to extend these to define an arbitrarily rich <b><i>Type System</i></b>. You
can think of a type system as an object schema for the CAS. </p>

<p>A type system defines the various types of objects that
may be discovered in documents and recorded by AEs. </p>

<p>As suggested above, Person may be defined as a type. Types
have properties or <b><i>features</i></b>. So for example, <i>Age</i> and <i>Occupation</i>
may be defined as features of the Person type.  </p>

<p>Other types might be <i>Organization, Company, Bank,
Facility, Money, Size, Price, Phone Number, Phone Call, Relation, Network
Packet, Product, Noun Phrase, Verb, Color, Parse Node, Feature Weight Array</i>
etc.  </p>

<p>There are no limits to the different types that may be
defined in a type system. A type system is domain and application specific. </p>

<p>Types in a UIMA type system may be organized into a
taxonomy. For example, <i>Company</i> may be defined as a subtype of <i>Organization</i>.
<i>NounPhrase</i> may be a subtype of a <i>ParseNode</i>.</p>

<h4>The Annotation
Type</h4>

<p>A general and common type used in artifact analysis and
from which additional types are often derived is the <b><i>annotation</i></b>
type. </p>

<p>The annotation type is used to annotate or label regions
of an artifact. Common artifacts are text documents, but they can be other
things, such as audio streams. The annotation type for text includes two
features, namely <i>begin</i> and <i>end</i>.  Values of these features represent integer offsets in the artifact and
delimit a span. Any particular annotation object identifies the span it
annotates with the <i>begin</i> and <i>end</i> features.  </p>

<p>The key idea here is that the annotation type is used to
identify and label or &ldquo;annotate&quot; a specific region of an artifact.</p>

<p>Consider that the Person type is defined as a subtype of
annotation.  An annotator, for example,
can create a Person annotation to record the discovery of a mention of a person
between position 141 and 143 in document D102. The annotator can create another
person annotation to record the detection of a mention of a person in the span
between positions 101 and 112. </p>

<h4>Not Just
Annotations</h4>

<p>While the annotation type is a useful type for annotating
regions of a document, annotations are not the only kind of types in a
CAS.  A CAS is a general representation
scheme and may store arbitrary data structures to represent the analysis of
documents.</p>

<p>As an example, consider statement 3 above (repeated here
for your convenience).</p>

<p class="xmp">(3) The Person denoted by span 101 to 112 and the Person denoted by span 141 to 143 in document D102 refer to the same Entity.</p>

<p>This statement mentions two person annotations in the CAS;
the first, call it P1 delimiting the span from 101 to 112 and the other, call
it P2, delimiting the span from 141 to 143. Statement 3 asserts explicitly that
these two spans refer to the same entity.  This means that while there are two expressions in the text represented
by the annotations P1 and P2, each refers to one and the same person. </p>

<p>The Entity type may be introduced into a type system to
capture this kind of information. The Entity type is not an annotation. It is
intended to represent an object in the domain which may be referred to by
different expressions (or mentions) occurring multiple times within a document
(or across documents within a collection of documents). The Entity type has a
feature named <i>occurrences. </i>This feature is used to point to all the
annotations believed to label mentions of the same entity.</p>

<p>Consider that the spans annotated by P1 and P2 were &quot;Fred
 Center&quot; and &quot;He&quot;
respectively. The annotator might create a new Entity object called <code>FredCenter</code>. To represent the relationship in statement 3
above, the annotator may link FredCenter to both P1 and P2 by making them
values of its <i>occurrences</i> feature.</p>

<p><a class="figReference" href="#_crossRef325">Figure
2</a> also illustrates that an entity may be linked to
annotations referring to regions of image documents as well. To do this the
annotation type would have to be extended with the appropriate features to
point to regions of an image.</p>

<h4>Multiple Views
within a CAS</h4>

<p>UIMA supports the simultaneous analysis of multiple views
of a document. This support comes in handy for processing multiple modalities, for
example, the audio and the closed captioned views of a single speech stream. </p>

<p>AEs analyze one or more views of a document. Each view
contains a specific <b><i>subject of analysis</i></b> (<b><i>Sofa</i></b>),
plus a set of indexes holding metadata indexed by that view. The CAS, overall,
holds one or more CAS Views, plus the descriptive objects that represent the
analysis results for each. </p>

<p>Another common example of using CAS Views is for different
translations of a document. Each translation may be represented with a
different CAS View. Each translation may be described by a different set of
analysis results. For more details on CAS Views and Sofas see <a class="crossrefText" href="SOFA_Developers_Guide.htm#_crossRef286">Chapter 8  </a> <a class="crossrefPage" href="SOFA_Developers_Guide.htm#_crossRef286"></a>.</p>

<h3><a id="_crossRef327">Interacting with the CAS and External Resources</a></h3>

<p>The two main interfaces that a UIMA component developer
interacts with are the CAS and the UIMA Context. </p>

<p>UIMA provides an efficient implementation of the CAS with
multiple programming interfaces. Through these interfaces, the annotator
developer interacts with the document and reads and writes analysis results.
The CAS interfaces provide a suite of access methods that allow the developer
to obtain indexed iterators to the different objects in the CAS. See <b><a class="crossrefText" href="CAS_Reference.htm#_crossRef77">Chapter 26, CAS Reference</a></b><i>.</i> While many objects may exist
in a CAS, the annotator developer can obtain a specialized iterator to all
Person objects associated with a particular view, for example.</p>

<p>For Java annotator developers, UIMA provides the JCas.
This interface provides the Java developer with a natural interface to CAS
objects. Each type declared in the type system appears as a Java Class.; the
UIMA framework renders the Person type as a Person class in Java. As the
analysis algorithm detects mentions of persons in the documents, it can create
Person objects in the CAS.  For more
details on how to interact with the CAS using this interface, refer to <i>Chapter 27  </i><a class="crossrefText" href="JCas_Reference.htm#_crossRef226"><b>JCas Reference</b></a>.</p>

<p>The component developer, in addition to interacting with
the CAS, can access external resources through the framework&rsquo;s resource manager
interface called the <b><i>UIMA Context</i></b>. This interface, among other
things, can ensure that different annotators working together in an aggregate
flow may share the same instance of an external file, for example. For details
on using the UIMA Context see <a class="crossrefText" href="Annotator_and_Analysis_Engine_Developers_Guide.htm#_crossRef1">Chapter 4, <b>Annotator
and Analysis Engine Developer&rsquo;s</b> Guide</a>.</p>

<h3><a id="_crossRef328">Component Descriptors</a></h3>

<p>UIMA defines interfaces for a small set of core components
that users of the framework provide implmentations for. Annotators and AEs are
two of the basic building blocks specified by the architecture.  Developers implement them to build and
compose analysis capabilities and ultimately applications.   </p>

<p>There are others components in addition to these, which we
will learn about later, but for every component specified in UIMA there are two
parts required for its implementation:</p>

<ol class="compact"><li>the declarative part and</li>


<li>the code part.
</li></ol>

<p>The declarative part contains metadata describing the
component, its identity, structure and behavior and is called the <b><i>Component
Descriptor</i></b>.  Component
descriptors are represented in XML. The code part implements the algorithm. The
code part may be a program in Java.</p>

<p>As a developer using the UIMA SDK, to implement a UIMA
component it is always the case that you will provide two things: the code part
and the Component Descriptor. Note that when you are composing an engine, the
code may be already provided in reusable subcomponents. In these cases you may
not be developing new code but rather composing an aggregate engine by pointing
to other components where the code has been included.</p>

<p>Component descriptors are represented in XML and aid in
component discovery, reuse, composition and development tooling.  The UIMA SDK provides tools for easily
creating and maintaining the component descriptors that relieve the developer
from editing XML directly. This tool is described briefly in <a class="crossrefText" href="Annotator_and_Analysis_Engine_Developers_Guide.htm#_crossRef1">Chapter
4, <b>Annotator and Analysis Engine Developer&rsquo;s
Guide</b></a>, and more thoroughly in <a class="crossrefText" href="Component_Descriptor_Editor_Users_Guide.htm#_crossRef96">Chapter
12, <b>Component
Descriptor Editor User&rsquo;s Guide</b></a>.</p>

<p>Component descriptors contain standard metadata including
the component&rsquo;s name, author, version, and a reference to the class that
implements the component. </p>

<p>In addition to these standard fields, a component
descriptor identifies the type system the component uses and the types it
requires in an input CAS and the types it plans to produce in an output CAS. </p>

<p>For example, an AE that detects person types may require
as input a CAS that includes a tokenization and deep parse of the document. The
descriptor refers to a type system to make the component&rsquo;s input requirements
and output types explicit. In effect, the descriptor includes a declarative
description of the component&rsquo;s behavior and can be used to aid in component
discovery and composition based on desired results.  UIMA analysis engines provide an interface
for accessing the component metadata represented in their descriptors. For more
details on the structure of UIMA component descriptors refer to <a class="crossrefText" href="Component_Descriptor_Reference.htm#_crossRef120">Chapter
23, <b>Component
Descriptor Reference</b></a>.</p>




  </subsection>
<subsection name="Aggregate Analysis Engines"><a id="_crossRef329"> </a>



<div class="keyConcept">

<p><b>Key UIMA Concepts
Introduced in this Section</b>: Aggregate Analysis Engine, Delegate Analysis
Engine, Tightly and Loosely Coupled, Flow Specification, Analysis Engine
Assembler</p>

</div>

<p><img alt="" width="588" height="168"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image006.png"/>
<a class="figCaption" id="_crossRef330">Sample Aggregate Analysis Engine</a>
</p>

<p>A simple or primitive UIMA Analysis Engine (AE) contains a
single annotator. AEs, however, may be defined to contain other AEs organized
in a workflow. These more complex analysis engines are called <b>Aggregate
Analysis Engines.</b> </p>

<p>Annotators tend to perform fairly granular functions, for
example language detection, tokenization or part of speech detection.  </p>

<p>Advanced analysis, however may involve an orchestration of
many of these primitive functions.  An AE
that performs named entity detection, for example, may include a pipeline of
annotators starting with language detection feeding tokenization, then
part-of-speech detection, then deep grammatical parsing and then finally
named-entity detection. Each step in the pipeline is required by the subsequent
analysis.  For example, the final
named-entity annotator can only do its analysis if the previous deep
grammatical parse was recorded in the CAS.</p>

<p>Aggregate AEs are built to encapsulate potentially complex
internal structure and insulate it from users of the AE. In our example, the
aggregate analysis engine developer simply acquires the internal components,
defines the necessary flow between them and publishes the resulting AE.
Consider the simple example illustrated in <a class="figReference" href="#_crossRef330">Figure
3</a> where &quot;MyNamed-EntityDetector&quot; is composed
of a linear flow of more primitive analysis engines.</p>

<p>Users of this AE need not have to know how it is
constructed internally but only its name and its published input requirements
and output types. These must be declared in the aggregate AE descriptor.  Aggregate AE&rsquo;s descriptors declare the
components they contain and a <b><i>flow specification</i></b>. The flow
specification defines the order in which the internal component AEs should be
run. The internal AEs specified in an aggregate are also called the <b><i>delegate
analysis engines.</i></b> </p>

<p>We refer to the development role associated with building
an aggregate from delegate AEs as the <b><i>Analysis Engine Assembler</i></b>. </p>

<p>The UIMA framework, given an aggregate analysis engine
descriptor, will run all delegate AEs, ensuring that each one gets access to the
CAS in the sequence produced by the flow specification.  The UIMA framework is equipped to handle
different deployments where the delegate engines, for example, are <b><i>tightly-coupled</i></b>
(running in the same process) or <b><i>loosely-coupled</i></b> (running in
separate processes or even on different machines).  The framework supports a number of remote
protocols for loose coupling deployments of aggregate analysis engines,
including SOAP (which stands for Simple Object Access Protocol, a standard Web
Services communications protocol). </p>

<p>The UIMA framework facilitates the deployment of AEs as
remote services by using an adapter layer that automatically creates the
necessary infrastructure in response to a declaration in the component&rsquo;s
descriptor. For more details on creating aggregate analysis engines refer to <a class="crossrefText" href="Component_Descriptor_Reference.htm#_crossRef120">Chapter
23, <b>Component
Descriptor Reference</b></a>. The component descriptor editor tool assists in
the specification of aggregate AEs from a repository of available engines. For
more details on this tool refer to <a class="crossrefText" href="Component_Descriptor_Editor_Users_Guide.htm#_crossRef96">Chapter
12, <b>Component
Descriptor Editor User&rsquo;s Guide</b></a>.</p>

<p>The UIMA framework implementation has built-in flow
supports for a linear flow between components, and one with  with conditional branching based on the
language of the document. It also supports user-provided flow controllers, as
described in <a class="crossrefText" href="FlowController_Developers_Guide.htm#_crossRef213">Chapter
7  </a> <a class="crossrefPage" href="FlowController_Developers_Guide.htm#_crossRef213"></a>. Furthermore, the application developer is free to
create multiple AEs and provide their own logic to combine the AEs in
arbitrarily complex flows.  For more
details on this the reader may refer to <a class="crossrefText" href="Application_Developers_Guide.htm#_crossRef44">Chapter
6, <b>Application
Developer&rsquo;s Guide</b></a>.</p>




  </subsection>
<subsection name="Application Building and Collection Processing"><a id="_crossRef331"> </a>



<div class="keyConcept">

<p><b>Key UIMA Concepts
Introduced in this Section</b>: Process Method, Collection Processing
Architecture, Collection Reader, CAS Consumer, CAS Initializer, Collection
Processing Engine, Collection Processing Manager.</p>

</div>

<h3><a id="_crossRef332">Using the framework from an
Application</a></h3>

<p><img alt="" width="618" height="418"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image008.png"/>
<a class="figCaption" id="_crossRef333">Using UIMA Framework to create
     and interact with an Analysis Engine</a>
As mentioned
above, the basic AE interface may be thought of as simply CAS in/CAS out.</p>

<p>The application is responsible for interacting with the UIMA
framework to instantiate an AE, create or acquire an input CAS, initialize the
input CAS with a document and then pass it to the AE through the <b><i>process
method</i></b>. This interaction with the framework is illustrated in <a class="figReference" href="#_crossRef333">Figure 4</a>. </p>

<p>The UIMA AE Factory takes the declarative information from
the Component Descriptor and the class files implementing the annotator, and
instantiates the AE instance, setting up the CAS and the UIMA Context.</p>

<p>The AE, possibly calling many delegate AEs internally, performs
the overall analysis and its process method returns the CAS containing new
analysis results. </p>

<p>The application then decides what to do with the returned
CAS. There are many possibilities. For instance the application could: display
the results, store the CAS to disk for post processing, extract and index
analysis results as part of a search or database application etc.</p>

<p>The UIMA framework provides methods to support the
application developer in creating and managing CASes and instantiating, running
and managing AEs. Details may be found in <a class="crossrefText" href="Application_Developers_Guide.htm#_crossRef44">Chapter
6, <b>Application
Developer&rsquo;s Guide</b></a></p>

<h3><a id="_crossRef334">Graduating to Collection
Processing</a></h3>

<p><img alt="" width="578" height="296"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image010.png"/>
<a class="figCaption" id="_crossRef335">High-Level UIMA Component
     Architecture from Source to Sink</a>
Many UIM
applications analyze entire collections of documents. They connect to different
document sources and do different things with the results. But in the typical
case, the application must generally follow these logical steps:</p>

<ol><li>Connect to a physical source</li>


<li>Acquire a document from the source</li>


<li>Initialize a CAS with the document
to be analyzed</li>


<li>Input the CAS to a selected
analysis engine</li>


<li>Process the resulting CAS</li>


<li>Go back to 2 until the collection
is processed</li>


<li>Do any final processing required
after all the documents in the collection have been analyzed
</li></ol>

<p>UIMA supports UIM application development for this general
type of processing through its <b>Collection Processing Architecture</b>.</p>

<p>As part of the collection processing architecture UIMA
introduces two primary components in addition to the annotator and analysis
engine. These are the <b>Collection Reader</b> and the <b>CAS Consumer</b>. The
complete flow from source, through document analysis, and to CAS Consumers
supported by UIMA is illustrated in <a class="figReference" href="#_crossRef335">Figure
5</a>.</p>

<p>The Collection Reader&rsquo;s job is to connect to and iterate
through a source collection, acquiring documents and initializing CASes for
analysis.  </p>

<p>Since the structure, access and iteration methods for
physical document sources vary independently from the format of stored
documents, UIMA defines another type of component called a <b>CAS Intializer</b>.  The CAS Initializer&rsquo;s job is specific to a
document format and specialized logic for mapping that format to a CAS. In the
simplest case a CAS Intializer may take the document provided by the containing
Collection Reader and insert it as a subject of analysis (or Sofa) in the
CAS.  A more advanced scenario is one
where the CAS Intializer may be implemented to handle documents that conform to
a certain XML schema and map some subset of the XML tags to CAS types and then
insert the de-tagged document content as the subject of analysis.  Collection Readers may reuse plug-in CAS
Initializers for different document formats.</p>

<p>CAS Consumers, as the name suggests, function at the end
of the flow. Their job is to do the final CAS processing. A CAS Consumer may be
implemented, for example, to index CAS contents in a search engine, extract
elements of interest and populate a relational database or serialize and store
analysis results to disk for subsequent and further analysis. </p>

<p>A Semantic Search engine is included in the UIMA SDK which
will allow the developer to experiment with indexing analysis results and
querying for documents based on all the annotations in the CAS. See the section
on integrating text analysis and search in <a class="crossrefText" href="Application_Developers_Guide.htm#_crossRef44">Chapter
6, <b>Application
Developer&rsquo;s Guide</b></a></p>

<p>A UIMA <b>Collection Processing Engine</b> (CPE) is an
aggregate component that specifies a &quot;source to sink&quot; flow from a
Collection Reader though a set of analysis engines and then to a set of CAS
Consumers. </p>

<p>CPEs are specified by XML files called CPE
Descriptors.  These are declarative
specifications that point to their contained components (Collection Readers,
analysis engines and CAS Consumers) and indicate a flow among them. The flow
specification allows for filtering capabilities to, for example, skip over AEs
based on CAS contents. Details about the format of CPE Descriptors may be found
in <a class="crossrefText" href="CPE_Descriptor_Reference.htm#_crossRef160">Chapter
24, <b>Collection
Processing Engine Descriptor Reference</b></a>. </p>

<p><img alt="" width="576" height="376"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image012.png"/>
<a class="figCaption" id="_crossRef336">Collection Processing Manager
     in UIMA Framework</a>
</p>

<p>The UIMA framework includes a <b>Collection Processing
Manager</b> (CPM). The CPM is capable of reading a CPE descriptor, and
deploying and running the specified CPE. <a class="figReference" href="#_crossRef336">Figure
6</a> illustrates the role of the CPM in the UIMA
Framework.</p>

<p>Key features of the CPM are failure recovery, CAS
management and scale-out. </p>

<p>Collections may be large and take considerable time to
analyze. A configurable behavior of the CPM is to log faults on single document
failures while continuing to process the collection.  This behavior is commonly used because analysis
components often tend to be the weakest link -- in practice they may choke on
strangely formatted content.  </p>

<p>This deployment option requires that the CPM run in a
separate process or a machine distinct from the CPE components.  A CPE may be configured to run with a variety
of deployment options that control the features provided by the CPM.  For details see <a class="crossrefText" href="CPE_Descriptor_Reference.htm#_crossRef160">Chapter
24, <b>Collection
Processing Engine Descriptor Reference</b></a>.</p>

<p>The UIMA SDK also provides a tool called the CPE
Configurator. This tool provides the developer with a user interface that
simplifies the process of connecting up all the components in a CPE and running
the result. For details on using the CPE Configurator see <a class="crossrefText" href="CPE_Configurator_Users_Manual.htm#_crossRef152">Chapter
13, <b>Collection
Processing Engine Configurator User's</b> Guide</a>. This tool currently does not provide access to
the full set of CPE deployment options supported by the CPM. Anything but the
default would have to be configured by editing the CPE descriptor directly. For
details on how to create and run CPEs refer to <i>Chapter 5  </i><i><b><a class="crossrefText" href="CPE_Developers_Guide.htm#_crossRef183">Collection Processing Engine Developer's
Guide</a></b></i>.</p>




  </subsection>
<subsection name="Exploiting Analysis Results"><a id="_crossRef337"> </a>



<div class="keyConcept">

<p><b>Key UIMA Concepts Introduced in this Section</b>: Semantic
Search, XML Fragment Queries.</p>

</div>

<h3><a id="_crossRef338">Semantic Search</a></h3>

<p>In a simple UIMA
Collection Processing Engine (CPE), a Collection Reader reads documents from
the file system and initializes CASs with their content. These are then fed to
an AE that annotates tokens and sentences, the CASs, now enriched with token
and sentence information, are passed to a CAS Consumer that populates a search
engine index. </p>

<p>The search engine
query processor can then use the token index to provide basic key-word
search.  For example, given a query
&ldquo;center&quot; the search engine would return all the documents that contained
the word &ldquo;center&quot;.</p>

<p><b><i>Semantic
Search</i></b> is a search paradigm that can exploit the more powerful
analytics pluggable in a UIMA CPE.</p>

<p>Consider that we
plugged a named-entity recognizer into the CPE described above. Assume this
analysis engine is capable of detecting in documents and annotating in the CAS
mentions of persons and organizations.</p>

<p>Complementing the
name-entity recognizer we add a CAS Consumer that extracts in addition to token
and sentence annotations, the person and organizations added to the CASs by the
name-entity detector. It then feeds these into the semantic search engine&rsquo;s
index.</p>

<p>The semantic
search engine that comes with the UIMA SDK, for example, can exploit this
addition information from the CAS to support more powerful queries. For example,
imagine a user is looking for documents that mention an organization with
&ldquo;center&quot; it is name but is not sure of the full or precise name of the
organization. A key-word search on &ldquo;center&quot; would likely produce way too
many documents because &ldquo;center&quot; is a common and ambiguous term.  The SDK&rsquo;s semantic search engine supports a
query language called <b><i>XML Fragments</i></b>. This query language is
designed to exploit the CAS annotations entered in its index. The XML Fragment
query, for example,</p>

<p class="xmp">&lt;organization&gt; center &lt;/organization&gt;</p>

<p>will produce
first only documents that contain &ldquo;center&quot; where it appears as part of a
mention annotated as an organization by the name-entity recognizer. This will
likely be a much shorter list of documents more precisely matching the user&rsquo;s
interest.</p>

<p>Consider taking
this one step further. We add a relationship recognizer that annotates mentions
of the CEO-of relationship. We configure the CAS Consumer so that it sends
these new relationship annotations to the semantic search index as well.  With these additional analysis results in the
index we can submit queries like</p>

<p class="xmp">&lt;ceo_of&gt;
    &lt;person&gt; center &lt;/person&gt;
    &lt;organization&gt; center &lt;/organization&gt;
&lt;ceo_of&gt;</p>

<p>This query will
precisely target documents that contain a mention of an organization with
&ldquo;center&quot; as part of its name where that organization is mentioned as part
of a <code>CEO-of</code>
relationship annotated by the relationship recognizer.</p>

<p>For more details
about using UIMA and Semantic Search see the section on integrating text
analysis and search in <a class="crossrefText" href="Application_Developers_Guide.htm#_crossRef44">Chapter
6, <b>Application
Developer&rsquo;s Guide</b></a></p>

<h3><a id="_crossRef339">Databases</a></h3>

<p>Search engine
indices are not the only place to deposit analysis results for use by
applications. Another classic example is populating databases.  While many approaches are possible with
varying degrees of flexibly and performance all are highly dependent on
application specifics. We included a simple sample CAS Consumer that provides
the basics for getting your analysis result into a relational database.  It extracts annotations from a CAS and writes
them to a relational database, using the open source Cloudscape / Apache Derby
database.</p>




  </subsection>
<subsection name="Multimodal Processing in UIMA"><a id="_crossRef340"> </a>



<p>In previous sections we've seen how the CAS is initialized
with an initial artifact that will be subsequently analyzed by Analysis engines
and CAS Consumers. The first Analysis engine may make some assertions about the
artifact, for example, in the form of annotations.  Subsequent Analysis engines will make further
assertions about both the artifact and previous analysis results, and finally
one or more CAS Consumers will extract information from these CASs for
structured information storage. <img alt="" width="576" height="264"
src="../UIMA_SDK_Guide_Ref/UIMA Conceputal Overview_files/image014.png"/>
<a class="figCaption" id="_crossRef341">Multiple Sofas in support of
     multi-modal analysis of an audio Stream. Some engines work on the audio
     &ldquo;view&quot;, some on the text &ldquo;view&quot; and some on both.</a>
</p>

<p>Consider a processing pipeline, illustrated in <a class="figReference" href="#_crossRef341">Figure 7</a>, that starts with an audio recording of a
conversation, transcribes the audio into text, and then extracts information
from the text transcript. Analysis Engines at the start of the pipeline are
analyzing an audio subject of analysis, and later analysis engines are
analyzing a text subject of analysis. The CAS Consumer will likely want to
build a search index from concepts found in the text to the original audio
segment covered by the concept.</p>

<p>What becomes clear from this relatively simple scenario is
that the CAS must be capable of simultaneously holding multiple subjects of
analysis. Some analysis engine will analyze only one subject of analysis, some
will analyze one and create another, and some will need to access multiple
subjects of analysis at the same time. </p>

<p>The support in UIMA for multiple subjects of analysis is
called <b><i>Sofa</i></b> support; Sofa is an acronym which is derived from <u>S</u>ubject
<u>of</u> <u>A</u>nalysis. In UIMA a Sofa may be associated with CAS
Views.  A particular CAS will have one or
more views, each view corresponding to a particular subject of analysis,
together with a set of the defined indexes that index the metadata created in
that view.</p>

<p>Analysis results can be indexed in, or &quot;belong&quot;
to, a specific view.  UIMA components may
be written in &quot;Multi-View&quot; mode - able to create and access multiple
Sofas at the same time, or in &quot;Single-View&quot; mode, simply receiving a
particular view of the CAS corresponding to a particular single Sofa. It is up
to the person assembling the component to supply the needed information to
insure a particular view is passed to the component at run time.  This is done using XML descriptors for Sofa
mapping (see <b><a class="crossrefText" href="SOFA_Developers_Guide.htm#_crossRef309">Sofa
Name Mapping</a></b> <a class="crossrefPage" href="SOFA_Developers_Guide.htm#_crossRef309"></a>).</p>

<p>Multi-View capability brings benefits to text-only
processing as well. An input document can be transformed from one format to
another.  Examples of this include
transforming text from HTML to plain text or from one natural language to
another. </p>




  </subsection>
<subsection name="Next Steps"><a id="_crossRef342"> </a>



<p>This chapter presented a high-level overview of UIMA
concepts. Along the way, it pointed to other documents in the UIMA SDK
documentation set where the reader can find details on how to apply the related
concepts in building applications with the UIMA SDK.</p>

<p>At this point the reader may return to the documentation
guide in <a class="crossrefText" href="UIMA SDK Overview.htm#_crossRef356">Chapter 1  </a> <a class="crossrefPage" href="UIMA SDK Overview.htm#_crossRef356"></a> to learn how they might proceed in getting started
using UIMA.</p>

<p>For a more detailed overview of the UIMA architecture,
framework and development roles we refer the reader to the following paper:</p>

<p>D. Ferrucci and A. Lally, &quot;Building an example
application using the Unstructured Information Management Architecture,&quot; <i>IBM
Systems Journal</i> <b>43</b>, No. 3, 455-475 (2004). </p>

<p>This paper can be found on line at <a
href="http://www.research.ibm.com/journal/sj43-3.html">http://www.research.ibm.com/journal/sj43-3.html</a></p>

</div>

<br/>


<div class="Section2">



</div>
<div class="footnotesHere"></div>
</div>





  </subsection>

</section>
</body>
</document>
